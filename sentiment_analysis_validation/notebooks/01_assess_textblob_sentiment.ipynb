{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import random\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('../data/hand_labeled_examples_short.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   35.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 246 ms, sys: 81.1 ms, total: 327 ms\n",
      "Wall time: 1min 51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 104 out of 104 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Analyze sentiments in parallel\n",
    "def process_sentiment(tweet):\n",
    "    return TextBlob(tweet, analyzer=NaiveBayesAnalyzer()).sentiment[0]\n",
    "\n",
    "n_cores = mp.cpu_count()\n",
    "sentiments = Parallel(n_jobs=n_cores, verbose=2)(delayed(process_sentiment)(tweet) for tweet in sample['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['pred']=[1 if sent=='neg' else 3 if sent=='pos' else 2 for sent in sentiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_baseline = 1.0 * sum(sample['sentiment']==2) / len(sample)\n",
    "accuracy_model = 1.0 * sum(sample['sentiment']==sample['pred']) / len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 47.12% when predicting all positives.\n",
      "Model accuracy of 26.92%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of {:.2%} when predicting all positives.'.format(accuracy_baseline))\n",
    "print('Model accuracy of {:.2%}'.format(accuracy_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 137 ms, sys: 60.4 ms, total: 198 ms\n",
      "Wall time: 2.04 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done 104 out of 104 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Repeat for pattern analyzer\n",
    "# Analyze sentiments in parallel\n",
    "def process_sentiment(tweet):\n",
    "    return TextBlob(tweet).sentiment.polarity\n",
    "\n",
    "n_cores = mp.cpu_count()\n",
    "sentiments = Parallel(n_jobs=n_cores, verbose=2)(delayed(process_sentiment)(tweet) for tweet in sample['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['pred']=[0 if sent<0.5 else 2 if sent>=0.5 else 1 for sent in sentiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_baseline = 1.0 * sum(sample['sentiment']==2) / len(sample)\n",
    "accuracy_model = 1.0 * sum(sample['sentiment']==sample['pred']) / len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 47.12% when predicting all positives.\n",
      "Model accuracy of 5.77%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of {:.2%} when predicting all positives.'.format(accuracy_baseline))\n",
    "print('Model accuracy of {:.2%}'.format(accuracy_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_fantasy",
   "language": "python",
   "name": "venv_fantasy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
