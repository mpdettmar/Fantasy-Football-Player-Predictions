{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defensive Features\n",
    "\n",
    "- 1, 3, and 5 week moving averages of defensive stats. Necessitates dropping first game from training set. If not enough games are present, we'll replicate the 1-day average.\n",
    "- 1, 3, 5 week minimums\n",
    "- 1, 3, 5 week maximums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_defense_moving_features(player_df, defense_df, windows=[1,3,5]):\n",
    "    moving_cols = defense_df.columns[2:]\n",
    "    defense_df_cp = defense_df.copy().rename(columns={'team':'opp'})\n",
    "    defense_df_cp.sort_values(['opp', 'date'], inplace=True)\n",
    "    for col in moving_cols:\n",
    "        for window in windows:\n",
    "            defense_df_cp['defense_{}_moving_avg_{}'.format(col,window)] = defense_df_cp.groupby('opp')['{}'.format(col)].transform(lambda x: x.rolling(window, 1).mean().shift())\n",
    "            defense_df_cp['defense_{}_moving_max_{}'.format(col,window)] = defense_df_cp.groupby('opp')['{}'.format(col)].transform(lambda x: x.rolling(window, 1).max().shift())\n",
    "            defense_df_cp['defense_{}_moving_min_{}'.format(col,window)] = defense_df_cp.groupby('opp')['{}'.format(col)].transform(lambda x: x.rolling(window, 1).min().shift())\n",
    "        defense_df_cp.drop(col, axis=1, inplace=True)\n",
    "    return player_df.merge(defense_df_cp, how='inner', on=['opp','date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather Features\n",
    "- Convert 'detail' to 'inclement' flag\n",
    "- Keep wind and temperature as is, but scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weather_features(player_df):\n",
    "    player_df_cp = player_df.copy()\n",
    "    player_df_cp['weather_inclement'] = ~((player_df_cp['weather_detail']=='DOME') | (pd.isnull(player_df_cp['weather_detail'])))\n",
    "    player_df_cp.drop(['weather_detail'], axis=1, inplace=True)\n",
    "    return player_df_cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter Features\n",
    "- Count player tweets in week before game\n",
    "- Count opponent tweets in week before game\n",
    "- % change in player tweets 3 days and 1 day before game\n",
    "- % change in opponent tweets 3 days and 1 day before game\n",
    "- Net sentiment player tweets in week before game\n",
    "- Net sentiment opponent tweets in week before game\n",
    "- Pct player opponent tweets\n",
    "- Pct neutral opponent tweets\n",
    "- % Change in net sentiment player tweets between 3 and 1 days of game\n",
    "- % Change in net sentiment opponent tweets between 3 and 1 days of game\n",
    "- % Change in pct neutral in player tweets between 3 and 1 days of game\n",
    "- % Change in pct neutral in player opponent between 3 and 1 days of game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_twitter_data(player_df, player_team, tweets_df):\n",
    "    # Get total tweets in a week for percentage stats\n",
    "    tweets_df['year_week'] = [week[0] + week[1] for week in zip(map(str, tweets_df['tweet_time_pac'].dt.year), map(str, tweets_df['week']))]\n",
    "    weekly_counts = tweets_df.groupby('year_week').agg({'tweet_id':'count'}).reset_index().rename(columns={'tweet_id': 'count_weekly_tweets'})\n",
    "    tweets_df = tweets_df.merge(weekly_counts, how='inner', on='year_week')\n",
    "    \n",
    "    tweets_df_filtered = tweets_df.loc[(tweets_df['team']==player_team) | (tweets_df['opp']==player_team)].copy()\n",
    "    tweets_df_filtered['opp'] = [teams[0] if teams[0] != player_team else teams[1] for teams in zip(tweets_df_filtered['team'], tweets_df_filtered['opp'])]\n",
    "    tweets_df_filtered['tweet_for_player'] = [1 if team==player_team else 0 for team in tweets_df_filtered['team']]\n",
    "    tweets_df_filtered['team'] = player_team\n",
    "    tweets_df_filtered.drop([\n",
    "        'home_away', \n",
    "        'score', \n",
    "        'opponent_score', \n",
    "        'point_spread', \n",
    "        'over_under',\n",
    "        'year_week'\n",
    "        ], axis=1, inplace=True)\n",
    "    return tweets_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_features = [\n",
    "            'twitter_pct_player_tweets',\n",
    "            'twitter_pct_opponent_tweets',\n",
    "            'twitter_count_player_swing_1_3',\n",
    "            'twitter_count_opponent_swing_1_3',\n",
    "            'twitter_player_net_sentiment',\n",
    "            'twitter_opponent_net_sentiment',\n",
    "            'twitter_player_pct_neutral',\n",
    "            'twitter_opponent_pct_neutral',\n",
    "            'twitter_net_sentiment_player_swing_1_3',\n",
    "            'twitter_net_sentiment_opponent_swing_1_3',\n",
    "            'twitter_pct_neutral_player_swing_1_3',\n",
    "            'twitter_pct_neutral_opponent_swing_1_3'\n",
    "        ]\n",
    "\n",
    "def generate_twitter_features(player_df, player_team, tweets_df, twitter_features):\n",
    "    tweets_df_mod = prep_twitter_data(player_df, player_team, tweets_df)\n",
    "    player_df['team'] = player_team\n",
    "    player_df['year_week'] = [week[0] + week[1] for week in zip(map(str, player_df['date'].dt.year), map(str, player_df['week']))]\n",
    "    tweets_df_mod = tweets_df_mod.merge(player_df, how='inner', on=['team', 'opp'])\n",
    "    \n",
    "    # Drop tweets from matchups not in the same time period\n",
    "    tweets_df_mod['timediff'] = tweets_df_mod['date'] - tweets_df_mod['tweet_time_pac']\n",
    "    tweets_df_mod = tweets_df_mod.loc[(tweets_df_mod['timediff']>pd.Timedelta('0 days')) & (tweets_df_mod['timediff']<pd.Timedelta('5 days'))]    \n",
    "    tweets_df_mod.drop_duplicates(inplace=True)\n",
    "    \n",
    "    def aggregate_features(df):\n",
    "        features = {}\n",
    "        features['twitter_pct_player_tweets'] = df.loc[df['tweet_for_player']==1]['tweet_id'].count() / df['count_weekly_tweets'].max()\n",
    "        features['twitter_pct_opponent_tweets'] = df.loc[df['tweet_for_player']==0]['tweet_id'].count() / df['count_weekly_tweets'].max()\n",
    "        features['count_player_1'] = df.loc[(df['tweet_for_player']==1) & (df['timediff'].dt.days==1)]['tweet_id'].count()\n",
    "        features['count_player_3'] = df.loc[(df['tweet_for_player']==1) & (df['timediff'].dt.days==3)]['tweet_id'].count()\n",
    "        features['twitter_count_player_swing_1_3'] = (features['count_player_1'] - features['count_player_3']) / features['count_player_3']\n",
    "        features['count_opponent_1'] = df.loc[(df['tweet_for_player']==0) & (df['timediff'].dt.days==1)]['tweet_id'].count()\n",
    "        features['count_opponent_3'] = df.loc[(df['tweet_for_player']==0) & (df['timediff'].dt.days==3)]['tweet_id'].count()\n",
    "        features['twitter_count_opponent_swing_1_3'] = (features['count_opponent_1'] - features['count_opponent_3']) / features['count_opponent_3']\n",
    "        features['twitter_player_net_sentiment'] = df.loc[df['tweet_for_player']==1]['sentiment'].mean()\n",
    "        features['twitter_opponent_net_sentiment'] = df.loc[df['tweet_for_player']==0]['sentiment'].mean()\n",
    "        features['twitter_player_pct_neutral'] = sum(df.loc[df['tweet_for_player']==1]['sentiment']==0) / df.loc[df['tweet_for_player']==1]['sentiment'].count()\n",
    "        features['twitter_opponent_pct_neutral'] = sum(df.loc[df['tweet_for_player']==0]['sentiment']==0) / df.loc[df['tweet_for_player']==1]['sentiment'].count()\n",
    "        features['net_sentiment_player_1'] = df.loc[(df['tweet_for_player']==1) & (df['timediff'].dt.days==1)]['sentiment'].mean()\n",
    "        features['net_sentiment_player_3'] = df.loc[(df['tweet_for_player']==1) & (df['timediff'].dt.days==3)]['sentiment'].mean()\n",
    "        features['twitter_net_sentiment_player_swing_1_3'] = (features['net_sentiment_player_1'] - features['net_sentiment_player_3']) / (features['net_sentiment_player_3'])\n",
    "        features['net_sentiment_opponent_1'] = df.loc[(df['tweet_for_player']==0) & (df['timediff'].dt.days==1)]['sentiment'].mean()\n",
    "        features['net_sentiment_opponent_3'] = df.loc[(df['tweet_for_player']==0) & (df['timediff'].dt.days==3)]['sentiment'].mean()\n",
    "        features['twitter_net_sentiment_opponent_swing_1_3'] = (features['net_sentiment_opponent_1'] - features['net_sentiment_opponent_3']) / (features['net_sentiment_opponent_3'])\n",
    "        features['pct_neutral_player_1'] = sum(df.loc[(df['tweet_for_player']==1) & (df['timediff'].dt.days==3)]['sentiment']==0) / df.loc[(df['tweet_for_player']==1) & (df['timediff'].dt.days==3)]['sentiment'].count()\n",
    "        features['pct_neutral_player_3'] = sum(df.loc[(df['tweet_for_player']==1) & (df['timediff'].dt.days==1)]['sentiment']==0) / df.loc[(df['tweet_for_player']==1) & (df['timediff'].dt.days==1)]['sentiment'].count()\n",
    "        features['twitter_pct_neutral_player_swing_1_3'] = (features['pct_neutral_player_1'] - features['pct_neutral_player_3']) / (features['pct_neutral_player_3'])\n",
    "        features['pct_neutral_opponent_1'] = sum(df.loc[(df['tweet_for_player']==0) & (df['timediff'].dt.days==3)]['sentiment']==0) / df.loc[(df['tweet_for_player']==0) & (df['timediff'].dt.days==3)]['sentiment'].count()\n",
    "        features['pct_neutral_opponent_3'] = sum(df.loc[(df['tweet_for_player']==0) & (df['timediff'].dt.days==1)]['sentiment']==0) / df.loc[(df['tweet_for_player']==0) & (df['timediff'].dt.days==1)]['sentiment'].count()\n",
    "        features['twitter_pct_neutral_opponent_swing_1_3'] = (features['pct_neutral_opponent_1'] - features['pct_neutral_opponent_3']) / (features['pct_neutral_opponent_3'])\n",
    "                                                      \n",
    "        features_ser = pd.Series(features, index=twitter_features)\n",
    "        return features_ser\n",
    "    \n",
    "    \n",
    "    tweets_df_mod_agg = tweets_df_mod.groupby(['year_week']).apply(aggregate_features).reset_index()\n",
    "    final_df = player_df.merge(tweets_df_mod_agg, how='inner', on='year_week')\n",
    "    final_df.drop(['year_week', 'team'], axis=1, inplace=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player Features\n",
    "- 1, 3, and 5 week averages of fantasy points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_player_moving_features(player_df, windows=[1,3,5]):\n",
    "    moving_cols = ['fantpt']\n",
    "    player_df_cp = player_df.copy()\n",
    "    for col in moving_cols:\n",
    "        for window in windows:\n",
    "            player_df_cp['player_{}_moving_avg_{}'.format(col,window)] = player_df_cp['{}'.format(col)].transform(lambda x: x.rolling(window, 1).mean().shift())\n",
    "            player_df_cp['player_{}_moving_max_{}'.format(col,window)] = player_df_cp['{}'.format(col)].transform(lambda x: x.rolling(window, 1).max().shift())\n",
    "            player_df_cp['player_{}_moving_min_{}'.format(col,window)] = player_df_cp['{}'.format(col)].transform(lambda x: x.rolling(window, 1).min().shift())\n",
    "            player_df_cp.rename(columns={'home':'player_home'}, inplace=True)\n",
    "    return player_df_cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betting features\n",
    "- Change 'favorite spread' to just 'spread' for relevant team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_betting_features(player_df):\n",
    "    player_df['betting_spread'] = [info[1] if info[0]==1 else abs(info[1]) for info in zip(player_df['favorite'], player_df['spread_favorite'])]\n",
    "    player_df.rename(columns = {'over_under_line':'betting_over_under_line'}, inplace=True)\n",
    "    return player_df.drop(['spread_favorite', 'favorite'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for baseline modeling\n",
    "defense = pd.read_csv('../data/data_modified/teams/defensive_stats.csv')\n",
    "brady = pd.read_csv('../data/data_modified/players/brady.csv')\n",
    "mccoy = pd.read_csv('../data/data_modified/players/mccoy.csv')\n",
    "\n",
    "defense['date']=pd.to_datetime(defense['date'])\n",
    "# Need to increment the year for January games by 1 because sportsreference API tags games by\n",
    "# season rather than actual date\n",
    "defense['date'] = [date.replace(year=date.year + 1) if date.month==1 else date for date in defense['date']]\n",
    "brady['date']=pd.to_datetime(brady['date'])\n",
    "mccoy['date']=pd.to_datetime(mccoy['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Twitter features for final modeling\n",
    "tweets = pd.read_csv('../data/data_modified/tweets/tweets_sentiment.csv')\n",
    "\n",
    "# Convert time columns to datetime\n",
    "# Convert UTC to Pacific time (to be safe - we don't have timestamps for the games,\n",
    "# but if we assume west coast time (where days start the latest), we will be sure to \n",
    "# avoid leakage)\n",
    "tweets['tweet_UTCtime'] = pd.to_datetime(tweets['tweet_UTCtime'])\n",
    "tweets.set_index(['tweet_UTCtime'], inplace=True)\n",
    "tweets['tweet_time_pac'] = tweets.index.tz_localize(pytz.utc).tz_convert('US/Pacific')\n",
    "\n",
    "# Rename cols\n",
    "tweets.rename(columns={'opponent':'opp'}, inplace=True)\n",
    "tweets.reset_index(drop=True, inplace=True)\n",
    "tweets['tweet_time_pac'] = tweets['tweet_time_pac'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:36: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:46: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "df_features=[]\n",
    "for key, df in {'NWE':brady, 'PHI':mccoy}.items():\n",
    "    feature_df = generate_defense_moving_features(df, defense)\n",
    "    feature_df = generate_weather_features(feature_df)\n",
    "    feature_df = generate_player_moving_features(feature_df)\n",
    "    feature_df = generate_betting_features(feature_df)\n",
    "    feature_df = generate_twitter_features(feature_df, key, tweets, twitter_features)\n",
    "    target = feature_df['fantpt']\n",
    "    feature_df.drop(['week', 'date', 'opp', 'fantpt'], axis=1, inplace=True)\n",
    "    feature_df = pd.concat([target,feature_df], axis=1)\n",
    "    feature_df.rename(columns={'fantpt':'target'}, inplace=True)\n",
    "    feature_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_features.append(feature_df)\n",
    "brady_all_features = df_features[0]\n",
    "mccoy_all_features = df_features[1]\n",
    "brady_baseline_features = df_features[0].drop(twitter_features, axis=1)\n",
    "mccoy_baseline_features = df_features[1].drop(twitter_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Save unscaled features for XGBoost\n",
    "# Scale features, drop moving averages, and save for RNN\n",
    "scaler = MinMaxScaler()\n",
    "for player, feat_dict in {'brady':{'baseline': brady_baseline_features, 'final':brady_all_features}, 'mccoy':{'baseline':mccoy_baseline_features, 'final':mccoy_all_features}}.items():\n",
    "        for feat_set, value in feat_dict.items():\n",
    "            value_cp = value.copy()\n",
    "            value_cp.drop(0, axis=0).to_csv('../data/data_final/{}/features_raw/{}.csv'.format(feat_set, player), index=False)\n",
    "            value_cp = value_cp.loc[:,['moving' not in col for col in value_cp.columns]]\n",
    "            scaler.fit(value_cp)\n",
    "            pd.concat([value_cp.iloc[:,0], pd.DataFrame(scaler.transform(value_cp)).iloc[:,1:]], axis=1).drop(0, axis=0).to_csv('../data/data_final/{}/features_scaled/{}.csv'.format(feat_set, player), index=False)\n",
    "                          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_fantasy",
   "language": "python",
   "name": "venv_fantasy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
