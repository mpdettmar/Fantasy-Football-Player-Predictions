{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost: First Model and Feature Importance\n",
    "\n",
    "In this notebook, we'll build the first of two baseline models: an XGBoost model for each player trained on 2010 and 2011, with 2012 as the test set.\n",
    "\n",
    "We'll then construct Shapley values to get a more intuitive sense of the most important features. Because of the high dimensionality of the data, we'll want our model to be very conservative.\n",
    "\n",
    "Note that I'm running the xgboost package on SageMaker because I have issues installing it locally. But this section should be done locally by most users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use kernel: conda_python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: - "
     ]
    }
   ],
   "source": [
    "!conda install -y -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y -c conda-forge shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tom Brady"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brady = pd.read_csv('../data/data_final/final/features_raw/brady.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = dt.date(2012,5,1)\n",
    "brady['date'] = pd.to_datetime(brady['date'])\n",
    "\n",
    "train, test = brady.loc[brady['date']<split_date, brady.columns!='date'], brady.loc[brady['date']>split_date, brady.columns!='date']\n",
    "X_train, y_train = train.iloc[:,1:], train.iloc[:,0]\n",
    "X_test, y_test = test.iloc[:,1:], test.iloc[:,0]\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 3, alpha = 10, n_estimators = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "print(\"RMSE: {:.2f}\\n MAE: {:.2f}\".format(rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "fig, ax = plt.subplots()\n",
    "plot1 = ax.plot(y_test.values, alpha = 0.8, label='actual')\n",
    "plot1 = ax.plot(preds, alpha = 0.8, label='predicted')\n",
    "ax.legend()\n",
    "plt.xlabel('Week (2012)')\n",
    "plt.ylabel('Fantasy Points')\n",
    "plt.title('Tom Brady Fantasy Points 2012, Predicted vs Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.25,'learning_rate': 0.4,\n",
    "                'max_depth': 4, 'alpha': 10}\n",
    "\n",
    "cv_results_rmse = xgb.cv(dtrain=dtrain, params=params, nfold=5,\n",
    "                    num_boost_round=100,early_stopping_rounds=20, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "cv_results_mae = xgb.cv(dtrain=dtrain, params=params, nfold=5,\n",
    "                    num_boost_round=100,early_stopping_rounds=20, metrics=\"mae\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cv_results_rmse.tail(1))\n",
    "print(cv_results_mae.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg2 = xgb.train(params=params, dtrain=dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = xg_reg2.predict(dtest)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds2))\n",
    "mae = mean_absolute_error(y_test, preds2)\n",
    "print(\"RMSE: {:.2f}\\n MAE: {:.2f}\".format(rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "fig, ax = plt.subplots()\n",
    "plot1 = ax.plot(y_test.values, alpha = 0.8, label='actual')\n",
    "plot1 = ax.plot(preds2, alpha = 0.8, label='predicted')\n",
    "ax.legend()\n",
    "plt.xlabel('Week (2012)')\n",
    "plt.ylabel('Fantasy Points')\n",
    "plt.title('Tom Brady Fantasy Points 2012, Predicted vs Actual (Model 2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap.TreeExplainer(xg_reg).shap_values(X_test), \n",
    "    features = X_test,\n",
    "    feature_names = X_train.columns, \n",
    "    max_display=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity of shap values for the defensive stats makes me think PCA would be really good here. It suggests that there may be a good amount of overlap between those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xg_reg)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[7], X_test.iloc[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, try iteratively training new models after each game to see how it improves prediciton accuracy. Use xg_reg as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_iter = X_train\n",
    "y_train_iter = y_train\n",
    "preds = []\n",
    "\n",
    "for game_idx in np.arange(0, len(X_test)):\n",
    "    xg_reg.fit(X_train_iter, y_train_iter)\n",
    "    preds.append(xg_reg.predict(X_test)[game_idx])\n",
    "    X_train_iter = X_train_iter.append(pd.Series(X_test.iloc[game_idx]))\n",
    "    y_train_iter = y_train_iter.append(pd.Series(y_test.iloc[game_idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "print(\"RMSE: {:.2f}\\n MAE: {:.2f}\".format(rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "fig, ax = plt.subplots()\n",
    "plot1 = ax.plot(y_test.values, alpha = 0.8, label='actual')\n",
    "plot1 = ax.plot(preds, alpha = 0.8, label='predicted')\n",
    "ax.legend()\n",
    "plt.xlabel('Week (2012)')\n",
    "plt.ylabel('Fantasy Points')\n",
    "plt.title('Tom Brady Fantasy Points 2012, Predicted vs Actual (Model 3 - Iterative Training)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McCoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mccoy = pd.read_csv('../data/data_final/final/features_raw/mccoy.csv')\n",
    "mccoy = mccoy.loc[mccoy['player_played']==1].copy() # we can drop the 'played' flag because we don't want ot predict these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = dt.date(2012,5,1)\n",
    "mccoy['date'] = pd.to_datetime(mccoy['date'])\n",
    "\n",
    "train, test = mccoy.loc[mccoy['date']<split_date, mccoy.columns!='date'], mccoy.loc[mccoy['date']>split_date, mccoy.columns!='date']\n",
    "X_train, y_train = train.iloc[:,1:], train.iloc[:,0]\n",
    "X_test, y_test = test.iloc[:,1:], test.iloc[:,0]\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 3, alpha = 10, n_estimators = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "print(\"RMSE: {:.2f}\\n MAE: {:.2f}\".format(rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "fig, ax = plt.subplots()\n",
    "plot1 = ax.plot(y_test.values, alpha = 0.8, label='actual')\n",
    "plot1 = ax.plot(preds, alpha = 0.8, label='predicted')\n",
    "ax.legend()\n",
    "plt.xlabel('Week (2012)')\n",
    "plt.ylabel('Fantasy Points')\n",
    "plt.title('LeSean McCoy Fantasy Points 2012, Predicted vs Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.25,'learning_rate': 0.6,\n",
    "                'max_depth': 2, 'alpha': 50}\n",
    "\n",
    "cv_results_rmse = xgb.cv(dtrain=dtrain, params=params, nfold=5,\n",
    "                    num_boost_round=100,early_stopping_rounds=20, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "cv_results_mae = xgb.cv(dtrain=dtrain, params=params, nfold=5,\n",
    "                    num_boost_round=100,early_stopping_rounds=20, metrics=\"mae\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_results_rmse.tail(1))\n",
    "print(cv_results_mae.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg2 = xgb.train(params=params, dtrain=dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = xg_reg2.predict(dtest)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds2))\n",
    "mae = mean_absolute_error(y_test, preds2)\n",
    "print(\"RMSE: {:.2f}\\n MAE: {:.2f}\".format(rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "fig, ax = plt.subplots()\n",
    "plot1 = ax.plot(y_test.values, alpha = 0.8, label='actual')\n",
    "plot1 = ax.plot(preds2, alpha = 0.8, label='predicted')\n",
    "ax.legend()\n",
    "plt.xlabel('Week (2012)')\n",
    "plt.ylabel('Fantasy Points')\n",
    "plt.title('LeSean McCoy Fantasy Points 2012, Predicted vs Actual (Model 2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap.TreeExplainer(xg_reg2).shap_values(X_test), \n",
    "    features = X_test,\n",
    "    feature_names = X_train.columns, \n",
    "    max_display=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xg_reg2)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[3], X_test.iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_iter = X_train\n",
    "y_train_iter = y_train\n",
    "preds = []\n",
    "\n",
    "for game_idx in np.arange(0, len(X_test)):\n",
    "    xg_reg.fit(X_train_iter, y_train_iter)\n",
    "    preds.append(xg_reg.predict(X_test)[game_idx])\n",
    "    X_train_iter = X_train_iter.append(pd.Series(X_test.iloc[game_idx]))\n",
    "    y_train_iter = y_train_iter.append(pd.Series(y_test.iloc[game_idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "print(\"RMSE: {:.2f}\\n MAE: {:.2f}\".format(rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "fig, ax = plt.subplots()\n",
    "plot1 = ax.plot(y_test.values, alpha = 0.8, label='actual')\n",
    "plot1 = ax.plot(preds, alpha = 0.8, label='predicted')\n",
    "ax.legend()\n",
    "plt.xlabel('Week (2012)')\n",
    "plt.ylabel('Fantasy Points')\n",
    "plt.title('LeSean McCoy Fantasy Points 2012, Predicted vs Actual (Model 3 - Iterative Training)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
