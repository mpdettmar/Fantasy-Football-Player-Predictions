{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use kernal conda_tensorflow_p36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tom Brady"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "brady = pd.read_csv('../data/data_final/final/features_raw/brady.csv')\n",
    "\n",
    "# Select features for RNN, along with target. Specifically, remove averages.\n",
    "features = [\n",
    "    'target',\n",
    "    'date',\n",
    "    'player_home',\n",
    "    'betting_over_under_line',\n",
    "    'betting_spread',\n",
    "    'weather_temperature',\n",
    "    'weather_wind_mph',\n",
    "    'weather_humidity',\n",
    "    'weather_inclement',\n",
    "    'defense_fumbles_forced_moving_avg_1',\n",
    "    'defense_fumbles_forced_moving_avg_3',\n",
    "    'defense_fumbles_forced_moving_avg_5',\n",
    "    'defense_interceptions_moving_avg_1',\n",
    "    'defense_interceptions_moving_avg_3',\n",
    "    'defense_interceptions_moving_avg_5',\n",
    "    'defense_pass_yards_allowed_moving_avg_1',\n",
    "    'defense_pass_yards_allowed_moving_avg_3',\n",
    "    'defense_pass_yards_allowed_moving_avg_5',\n",
    "    'defense_rush_yards_allowed_moving_avg_1',\n",
    "    'defense_rush_yards_allowed_moving_avg_3',\n",
    "    'defense_rush_yards_allowed_moving_avg_5',\n",
    "    'defense_sacks_moving_avg_1',\n",
    "    'defense_sacks_moving_avg_3',\n",
    "    'defense_sacks_moving_avg_5',\n",
    "    'defense_points_allowed_moving_avg_1',\n",
    "    'defense_points_allowed_moving_avg_3',\n",
    "    'defense_points_allowed_moving_avg_5',\n",
    "    'twitter_pct_player_tweets',\n",
    "    'twitter_pct_opponent_tweets',\n",
    "    'twitter_count_player_swing_1_3',\n",
    "    'twitter_count_opponent_swing_1_3',\n",
    "    'twitter_player_net_sentiment',\n",
    "    'twitter_opponent_net_sentiment',\n",
    "    'twitter_player_pct_neutral',\n",
    "    'twitter_opponent_pct_neutral',\n",
    "    'twitter_net_sentiment_player_swing_1_3',\n",
    "    'twitter_net_sentiment_opponent_swing_1_3',\n",
    "    'twitter_pct_neutral_player_swing_1_3',\n",
    "    'twitter_pct_neutral_opponent_swing_1_3'\n",
    "]\n",
    "\n",
    "brady = brady.loc[:, features]\n",
    "brady['date'] = pd.to_datetime(brady['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each column in X, replace NaNs with training set naive Bayes\n",
    "def replace_nans_mean(df, split):\n",
    "    df_cp = df.copy()\n",
    "    for col in df_cp.columns:\n",
    "        if col == 'date':\n",
    "            continue\n",
    "        naive_estimate = df_cp.loc[:split, col].mean()\n",
    "        df_cp.loc[pd.isnull(df_cp[col]), col] = naive_estimate\n",
    "        \n",
    "    return df_cp\n",
    "        \n",
    "brady = replace_nans_mean(brady, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype bool, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Train + test set indices\n",
    "split_date = pd.Timestamp(2012,5,1)\n",
    "train_idx = brady.loc[brady['date']<split_date].index.values\n",
    "test_idx = brady.loc[brady['date']>split_date].index.values\n",
    "\n",
    "# Scale Features\n",
    "brady.drop('date', axis=1, inplace=True)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(brady)\n",
    "brady = scaler.transform(brady)\n",
    "\n",
    "# Train + test sets\n",
    "train, test = brady[train_idx], brady[test_idx]\n",
    "\n",
    "# Split to X and Y\n",
    "# X_train, X_test, y_train, y_test = X, y = brady.iloc[:,1:], brady.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_data(df, window):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df)-window):\n",
    "        temp_set = df[i:(i+window)].copy()\n",
    "        X.append(temp_set[:,1:])\n",
    "        y.append(temp_set[window-1,0])\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test sets\n",
    "window = 5\n",
    "X, y = build_lstm_data(brady, window)\n",
    "X_train, y_train = X[(train_idx-window)[window:]], y[(train_idx-window)[window:]]\n",
    "X_test, y_test = X[(test_idx-window)], y[(test_idx-window)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert scaling of y for testing comparison\n",
    "y_inv = np.concatenate((y_test.reshape(len(y_test),1), test[:,1:]), axis=1)\n",
    "y_inv = scaler.inverse_transform(y_inv)\n",
    "y_inv = y_inv[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1106 00:52:42.651103 140091925624640 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1106 00:52:44.377763 140091925624640 deprecation.py:506] From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1106 00:52:46.134674 140091925624640 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1106 00:52:48.412560 140091925624640 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26 samples, validate on 16 samples\n",
      "Epoch 1/1000\n",
      " - 37s - loss: 0.3163 - val_loss: 0.2038\n",
      "Epoch 2/1000\n",
      " - 1s - loss: 0.2582 - val_loss: 0.2317\n",
      "Epoch 3/1000\n",
      " - 1s - loss: 0.2673 - val_loss: 0.2385\n",
      "Epoch 4/1000\n",
      " - 1s - loss: 0.2442 - val_loss: 0.2142\n",
      "Epoch 5/1000\n",
      " - 1s - loss: 0.2338 - val_loss: 0.2085\n",
      "Epoch 6/1000\n",
      " - 1s - loss: 0.2092 - val_loss: 0.2093\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 0.2460 - val_loss: 0.2112\n",
      "Epoch 8/1000\n",
      " - 1s - loss: 0.2323 - val_loss: 0.2129\n",
      "Epoch 9/1000\n",
      " - 1s - loss: 0.2267 - val_loss: 0.2147\n",
      "Epoch 10/1000\n",
      " - 1s - loss: 0.2646 - val_loss: 0.2193\n",
      "Epoch 11/1000\n",
      " - 1s - loss: 0.2538 - val_loss: 0.2231\n",
      "Epoch 12/1000\n",
      " - 1s - loss: 0.2466 - val_loss: 0.2164\n",
      "Epoch 13/1000\n",
      " - 1s - loss: 0.2371 - val_loss: 0.2155\n",
      "Epoch 14/1000\n",
      " - 1s - loss: 0.2142 - val_loss: 0.2103\n",
      "Epoch 15/1000\n",
      " - 1s - loss: 0.2206 - val_loss: 0.2050\n",
      "Epoch 16/1000\n",
      " - 1s - loss: 0.2221 - val_loss: 0.2037\n",
      "Epoch 17/1000\n",
      " - 1s - loss: 0.2391 - val_loss: 0.2110\n",
      "Epoch 18/1000\n",
      " - 1s - loss: 0.2353 - val_loss: 0.2347\n",
      "Epoch 19/1000\n",
      " - 1s - loss: 0.1878 - val_loss: 0.2441\n",
      "Epoch 20/1000\n",
      " - 1s - loss: 0.1978 - val_loss: 0.2348\n",
      "Epoch 21/1000\n",
      " - 1s - loss: 0.2230 - val_loss: 0.2210\n",
      "Epoch 22/1000\n",
      " - 1s - loss: 0.1656 - val_loss: 0.2318\n",
      "Epoch 23/1000\n",
      " - 1s - loss: 0.1853 - val_loss: 0.2448\n",
      "Epoch 24/1000\n",
      " - 1s - loss: 0.1983 - val_loss: 0.2686\n",
      "Epoch 25/1000\n",
      " - 1s - loss: 0.1751 - val_loss: 0.2789\n",
      "Epoch 26/1000\n",
      " - 1s - loss: 0.1783 - val_loss: 0.2560\n",
      "Epoch 27/1000\n",
      " - 1s - loss: 0.1758 - val_loss: 0.2160\n",
      "Epoch 28/1000\n",
      " - 1s - loss: 0.2039 - val_loss: 0.2474\n",
      "Epoch 29/1000\n",
      " - 1s - loss: 0.1762 - val_loss: 0.2219\n",
      "Epoch 30/1000\n",
      " - 1s - loss: 0.1972 - val_loss: 0.2638\n",
      "Epoch 31/1000\n",
      " - 1s - loss: 0.1919 - val_loss: 0.2465\n",
      "Epoch 32/1000\n",
      " - 1s - loss: 0.2145 - val_loss: 0.2205\n",
      "Epoch 33/1000\n",
      " - 1s - loss: 0.1847 - val_loss: 0.2550\n",
      "Epoch 34/1000\n",
      " - 1s - loss: 0.1764 - val_loss: 0.2204\n",
      "Epoch 35/1000\n",
      " - 1s - loss: 0.1648 - val_loss: 0.2297\n",
      "Epoch 36/1000\n",
      " - 1s - loss: 0.1800 - val_loss: 0.2772\n",
      "Epoch 37/1000\n",
      " - 1s - loss: 0.1945 - val_loss: 0.2948\n",
      "Epoch 38/1000\n",
      " - 1s - loss: 0.1735 - val_loss: 0.2525\n",
      "Epoch 39/1000\n",
      " - 1s - loss: 0.1749 - val_loss: 0.2607\n",
      "Epoch 40/1000\n",
      " - 1s - loss: 0.1898 - val_loss: 0.2911\n",
      "Epoch 41/1000\n",
      " - 1s - loss: 0.1569 - val_loss: 0.2715\n",
      "Epoch 42/1000\n",
      " - 1s - loss: 0.1645 - val_loss: 0.2293\n",
      "Epoch 43/1000\n",
      " - 1s - loss: 0.1503 - val_loss: 0.2647\n",
      "Epoch 44/1000\n",
      " - 1s - loss: 0.1713 - val_loss: 0.2423\n",
      "Epoch 45/1000\n",
      " - 1s - loss: 0.1724 - val_loss: 0.2452\n",
      "Epoch 46/1000\n",
      " - 1s - loss: 0.1539 - val_loss: 0.3311\n",
      "Epoch 47/1000\n",
      " - 1s - loss: 0.1599 - val_loss: 0.2049\n",
      "Epoch 48/1000\n",
      " - 1s - loss: 0.2015 - val_loss: 0.1871\n",
      "Epoch 49/1000\n",
      " - 1s - loss: 0.1585 - val_loss: 0.2499\n",
      "Epoch 50/1000\n",
      " - 1s - loss: 0.1369 - val_loss: 0.2672\n",
      "Epoch 51/1000\n",
      " - 1s - loss: 0.1656 - val_loss: 0.2793\n",
      "Epoch 52/1000\n",
      " - 1s - loss: 0.1580 - val_loss: 0.2368\n",
      "Epoch 53/1000\n",
      " - 1s - loss: 0.1465 - val_loss: 0.2484\n",
      "Epoch 54/1000\n",
      " - 1s - loss: 0.1296 - val_loss: 0.2431\n",
      "Epoch 55/1000\n",
      " - 1s - loss: 0.1610 - val_loss: 0.2359\n",
      "Epoch 56/1000\n",
      " - 1s - loss: 0.1599 - val_loss: 0.3189\n",
      "Epoch 57/1000\n",
      " - 1s - loss: 0.1892 - val_loss: 0.2978\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 0.1733 - val_loss: 0.1890\n",
      "Epoch 59/1000\n",
      " - 1s - loss: 0.1804 - val_loss: 0.2450\n",
      "Epoch 60/1000\n",
      " - 1s - loss: 0.1642 - val_loss: 0.3573\n",
      "Epoch 61/1000\n",
      " - 1s - loss: 0.1714 - val_loss: 0.3115\n",
      "Epoch 62/1000\n",
      " - 1s - loss: 0.1579 - val_loss: 0.2624\n",
      "Epoch 63/1000\n",
      " - 1s - loss: 0.1404 - val_loss: 0.2628\n",
      "Epoch 64/1000\n",
      " - 1s - loss: 0.1319 - val_loss: 0.2821\n",
      "Epoch 65/1000\n",
      " - 1s - loss: 0.1536 - val_loss: 0.2575\n",
      "Epoch 66/1000\n",
      " - 1s - loss: 0.1372 - val_loss: 0.3142\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 0.1341 - val_loss: 0.2470\n",
      "Epoch 68/1000\n",
      " - 1s - loss: 0.1486 - val_loss: 0.2465\n",
      "Epoch 69/1000\n",
      " - 1s - loss: 0.1382 - val_loss: 0.2531\n",
      "Epoch 70/1000\n",
      " - 1s - loss: 0.1411 - val_loss: 0.2932\n",
      "Epoch 71/1000\n",
      " - 1s - loss: 0.1542 - val_loss: 0.3146\n",
      "Epoch 72/1000\n",
      " - 1s - loss: 0.1220 - val_loss: 0.2718\n",
      "Epoch 73/1000\n",
      " - 1s - loss: 0.1461 - val_loss: 0.2557\n",
      "Epoch 74/1000\n",
      " - 1s - loss: 0.1431 - val_loss: 0.3389\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 0.1495 - val_loss: 0.2586\n",
      "Epoch 76/1000\n",
      " - 1s - loss: 0.1409 - val_loss: 0.2394\n",
      "Epoch 77/1000\n",
      " - 1s - loss: 0.1341 - val_loss: 0.2527\n",
      "Epoch 78/1000\n",
      " - 1s - loss: 0.1332 - val_loss: 0.2924\n",
      "Epoch 79/1000\n",
      " - 1s - loss: 0.1269 - val_loss: 0.3160\n",
      "Epoch 80/1000\n",
      " - 1s - loss: 0.1350 - val_loss: 0.2499\n",
      "Epoch 81/1000\n",
      " - 1s - loss: 0.1554 - val_loss: 0.3288\n",
      "Epoch 82/1000\n",
      " - 1s - loss: 0.1774 - val_loss: 0.2922\n",
      "Epoch 83/1000\n",
      " - 1s - loss: 0.1272 - val_loss: 0.2256\n",
      "Epoch 84/1000\n",
      " - 1s - loss: 0.1791 - val_loss: 0.2152\n",
      "Epoch 85/1000\n",
      " - 1s - loss: 0.1473 - val_loss: 0.2985\n",
      "Epoch 86/1000\n",
      " - 1s - loss: 0.1251 - val_loss: 0.2328\n",
      "Epoch 87/1000\n",
      " - 1s - loss: 0.1392 - val_loss: 0.2786\n",
      "Epoch 88/1000\n",
      " - 1s - loss: 0.1448 - val_loss: 0.3010\n",
      "Epoch 89/1000\n",
      " - 1s - loss: 0.1125 - val_loss: 0.2391\n",
      "Epoch 90/1000\n",
      " - 1s - loss: 0.1440 - val_loss: 0.2767\n",
      "Epoch 91/1000\n",
      " - 1s - loss: 0.1439 - val_loss: 0.3385\n",
      "Epoch 92/1000\n",
      " - 1s - loss: 0.1274 - val_loss: 0.3307\n",
      "Epoch 93/1000\n",
      " - 1s - loss: 0.1280 - val_loss: 0.2489\n",
      "Epoch 94/1000\n",
      " - 1s - loss: 0.1441 - val_loss: 0.2319\n",
      "Epoch 95/1000\n",
      " - 1s - loss: 0.1503 - val_loss: 0.3054\n",
      "Epoch 96/1000\n",
      " - 1s - loss: 0.1384 - val_loss: 0.2621\n",
      "Epoch 97/1000\n",
      " - 1s - loss: 0.1248 - val_loss: 0.2635\n",
      "Epoch 98/1000\n",
      " - 0s - loss: 0.1265 - val_loss: 0.2915\n",
      "Epoch 99/1000\n",
      " - 1s - loss: 0.1285 - val_loss: 0.2787\n",
      "Epoch 100/1000\n",
      " - 1s - loss: 0.1059 - val_loss: 0.2637\n",
      "Epoch 101/1000\n",
      " - 1s - loss: 0.1496 - val_loss: 0.2414\n",
      "Epoch 102/1000\n",
      " - 1s - loss: 0.1189 - val_loss: 0.2379\n",
      "Epoch 103/1000\n",
      " - 1s - loss: 0.1236 - val_loss: 0.2219\n",
      "Epoch 104/1000\n",
      " - 1s - loss: 0.1318 - val_loss: 0.2469\n",
      "Epoch 105/1000\n",
      " - 1s - loss: 0.1057 - val_loss: 0.2398\n",
      "Epoch 106/1000\n",
      " - 1s - loss: 0.1096 - val_loss: 0.2222\n",
      "Epoch 107/1000\n",
      " - 1s - loss: 0.1124 - val_loss: 0.3138\n",
      "Epoch 108/1000\n",
      " - 1s - loss: 0.1251 - val_loss: 0.3080\n",
      "Epoch 109/1000\n",
      " - 1s - loss: 0.1088 - val_loss: 0.2196\n",
      "Epoch 110/1000\n",
      " - 1s - loss: 0.1163 - val_loss: 0.2754\n",
      "Epoch 111/1000\n",
      " - 1s - loss: 0.1479 - val_loss: 0.3449\n",
      "Epoch 112/1000\n",
      " - 1s - loss: 0.1354 - val_loss: 0.2761\n",
      "Epoch 113/1000\n",
      " - 1s - loss: 0.1176 - val_loss: 0.2441\n",
      "Epoch 114/1000\n",
      " - 1s - loss: 0.1166 - val_loss: 0.2230\n",
      "Epoch 115/1000\n",
      " - 1s - loss: 0.1197 - val_loss: 0.2288\n",
      "Epoch 116/1000\n",
      " - 1s - loss: 0.1190 - val_loss: 0.2251\n",
      "Epoch 117/1000\n",
      " - 1s - loss: 0.1228 - val_loss: 0.2286\n",
      "Epoch 118/1000\n",
      " - 1s - loss: 0.1448 - val_loss: 0.2958\n",
      "Epoch 119/1000\n",
      " - 1s - loss: 0.1480 - val_loss: 0.2521\n",
      "Epoch 120/1000\n",
      " - 1s - loss: 0.1243 - val_loss: 0.1883\n",
      "Epoch 121/1000\n",
      " - 1s - loss: 0.1321 - val_loss: 0.2188\n",
      "Epoch 122/1000\n",
      " - 1s - loss: 0.1181 - val_loss: 0.2548\n",
      "Epoch 123/1000\n",
      " - 1s - loss: 0.1176 - val_loss: 0.2567\n",
      "Epoch 124/1000\n",
      " - 1s - loss: 0.1228 - val_loss: 0.2241\n",
      "Epoch 125/1000\n",
      " - 1s - loss: 0.1109 - val_loss: 0.2334\n",
      "Epoch 126/1000\n",
      " - 1s - loss: 0.0988 - val_loss: 0.2093\n",
      "Epoch 127/1000\n",
      " - 1s - loss: 0.1338 - val_loss: 0.2303\n",
      "Epoch 128/1000\n",
      " - 1s - loss: 0.1211 - val_loss: 0.2330\n",
      "Epoch 129/1000\n",
      " - 1s - loss: 0.1087 - val_loss: 0.2109\n",
      "Epoch 130/1000\n",
      " - 1s - loss: 0.0914 - val_loss: 0.2284\n",
      "Epoch 131/1000\n",
      " - 1s - loss: 0.1160 - val_loss: 0.2139\n",
      "Epoch 132/1000\n",
      " - 1s - loss: 0.1074 - val_loss: 0.2153\n",
      "Epoch 133/1000\n",
      " - 1s - loss: 0.1013 - val_loss: 0.2492\n",
      "Epoch 134/1000\n",
      " - 1s - loss: 0.0870 - val_loss: 0.2286\n",
      "Epoch 135/1000\n",
      " - 1s - loss: 0.1115 - val_loss: 0.2330\n",
      "Epoch 136/1000\n",
      " - 0s - loss: 0.1306 - val_loss: 0.2847\n",
      "Epoch 137/1000\n",
      " - 0s - loss: 0.1202 - val_loss: 0.2445\n",
      "Epoch 138/1000\n",
      " - 0s - loss: 0.1010 - val_loss: 0.2439\n",
      "Epoch 139/1000\n",
      " - 0s - loss: 0.1359 - val_loss: 0.3343\n",
      "Epoch 140/1000\n",
      " - 0s - loss: 0.1159 - val_loss: 0.2966\n",
      "Epoch 141/1000\n",
      " - 0s - loss: 0.1162 - val_loss: 0.2513\n",
      "Epoch 142/1000\n",
      " - 0s - loss: 0.1263 - val_loss: 0.2731\n",
      "Epoch 143/1000\n",
      " - 0s - loss: 0.1021 - val_loss: 0.2808\n",
      "Epoch 144/1000\n",
      " - 0s - loss: 0.1022 - val_loss: 0.2336\n",
      "Epoch 145/1000\n",
      " - 0s - loss: 0.1233 - val_loss: 0.2203\n",
      "Epoch 146/1000\n",
      " - 0s - loss: 0.0979 - val_loss: 0.2361\n",
      "Epoch 147/1000\n",
      " - 0s - loss: 0.1261 - val_loss: 0.2178\n",
      "Epoch 148/1000\n",
      " - 0s - loss: 0.1039 - val_loss: 0.2769\n",
      "Epoch 149/1000\n",
      " - 0s - loss: 0.1118 - val_loss: 0.2263\n",
      "Epoch 150/1000\n",
      " - 0s - loss: 0.1009 - val_loss: 0.2121\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1295 - val_loss: 0.2104\n",
      "Epoch 152/1000\n",
      " - 0s - loss: 0.1124 - val_loss: 0.2749\n",
      "Epoch 153/1000\n",
      " - 0s - loss: 0.1091 - val_loss: 0.2171\n",
      "Epoch 154/1000\n",
      " - 0s - loss: 0.0902 - val_loss: 0.2377\n",
      "Epoch 155/1000\n",
      " - 0s - loss: 0.0983 - val_loss: 0.2445\n",
      "Epoch 156/1000\n",
      " - 0s - loss: 0.0730 - val_loss: 0.2655\n",
      "Epoch 157/1000\n",
      " - 0s - loss: 0.1078 - val_loss: 0.2128\n",
      "Epoch 158/1000\n",
      " - 0s - loss: 0.1167 - val_loss: 0.2330\n",
      "Epoch 159/1000\n",
      " - 0s - loss: 0.1303 - val_loss: 0.2738\n",
      "Epoch 160/1000\n",
      " - 0s - loss: 0.1119 - val_loss: 0.2757\n",
      "Epoch 161/1000\n",
      " - 0s - loss: 0.1180 - val_loss: 0.2142\n",
      "Epoch 162/1000\n",
      " - 0s - loss: 0.1241 - val_loss: 0.2329\n",
      "Epoch 163/1000\n",
      " - 0s - loss: 0.1084 - val_loss: 0.2329\n",
      "Epoch 164/1000\n",
      " - 0s - loss: 0.1279 - val_loss: 0.2240\n",
      "Epoch 165/1000\n",
      " - 0s - loss: 0.0941 - val_loss: 0.2348\n",
      "Epoch 166/1000\n",
      " - 0s - loss: 0.1079 - val_loss: 0.2252\n",
      "Epoch 167/1000\n",
      " - 0s - loss: 0.0988 - val_loss: 0.2365\n",
      "Epoch 168/1000\n",
      " - 0s - loss: 0.1101 - val_loss: 0.2047\n",
      "Epoch 169/1000\n",
      " - 0s - loss: 0.1300 - val_loss: 0.1949\n",
      "Epoch 170/1000\n",
      " - 0s - loss: 0.1017 - val_loss: 0.2293\n",
      "Epoch 171/1000\n",
      " - 0s - loss: 0.0840 - val_loss: 0.2089\n",
      "Epoch 172/1000\n",
      " - 0s - loss: 0.1001 - val_loss: 0.2056\n",
      "Epoch 173/1000\n",
      " - 0s - loss: 0.1006 - val_loss: 0.2087\n",
      "Epoch 174/1000\n",
      " - 0s - loss: 0.1135 - val_loss: 0.2750\n",
      "Epoch 175/1000\n",
      " - 0s - loss: 0.1317 - val_loss: 0.2608\n",
      "Epoch 176/1000\n",
      " - 0s - loss: 0.0868 - val_loss: 0.2251\n",
      "Epoch 177/1000\n",
      " - 0s - loss: 0.1157 - val_loss: 0.2161\n",
      "Epoch 178/1000\n",
      " - 0s - loss: 0.1187 - val_loss: 0.2018\n",
      "Epoch 179/1000\n",
      " - 0s - loss: 0.0897 - val_loss: 0.2575\n",
      "Epoch 180/1000\n",
      " - 0s - loss: 0.0947 - val_loss: 0.2108\n",
      "Epoch 181/1000\n",
      " - 0s - loss: 0.1259 - val_loss: 0.1930\n",
      "Epoch 182/1000\n",
      " - 0s - loss: 0.1018 - val_loss: 0.2351\n",
      "Epoch 183/1000\n",
      " - 0s - loss: 0.1066 - val_loss: 0.2207\n",
      "Epoch 184/1000\n",
      " - 0s - loss: 0.1097 - val_loss: 0.2348\n",
      "Epoch 185/1000\n",
      " - 0s - loss: 0.0877 - val_loss: 0.2822\n",
      "Epoch 186/1000\n",
      " - 0s - loss: 0.1035 - val_loss: 0.2215\n",
      "Epoch 187/1000\n",
      " - 0s - loss: 0.1449 - val_loss: 0.2008\n",
      "Epoch 188/1000\n",
      " - 0s - loss: 0.0914 - val_loss: 0.2515\n",
      "Epoch 189/1000\n",
      " - 0s - loss: 0.1231 - val_loss: 0.2156\n",
      "Epoch 190/1000\n",
      " - 0s - loss: 0.1086 - val_loss: 0.1965\n",
      "Epoch 191/1000\n",
      " - 0s - loss: 0.0918 - val_loss: 0.2214\n",
      "Epoch 192/1000\n",
      " - 0s - loss: 0.0916 - val_loss: 0.2461\n",
      "Epoch 193/1000\n",
      " - 0s - loss: 0.0921 - val_loss: 0.2007\n",
      "Epoch 194/1000\n",
      " - 0s - loss: 0.1030 - val_loss: 0.2317\n",
      "Epoch 195/1000\n",
      " - 0s - loss: 0.1316 - val_loss: 0.2879\n",
      "Epoch 196/1000\n",
      " - 0s - loss: 0.0950 - val_loss: 0.2449\n",
      "Epoch 197/1000\n",
      " - 0s - loss: 0.0844 - val_loss: 0.2426\n",
      "Epoch 198/1000\n",
      " - 0s - loss: 0.0763 - val_loss: 0.2397\n",
      "Epoch 199/1000\n",
      " - 0s - loss: 0.0994 - val_loss: 0.2438\n",
      "Epoch 200/1000\n",
      " - 0s - loss: 0.0959 - val_loss: 0.2111\n",
      "Epoch 201/1000\n",
      " - 0s - loss: 0.0674 - val_loss: 0.2647\n",
      "Epoch 202/1000\n",
      " - 0s - loss: 0.1147 - val_loss: 0.2336\n",
      "Epoch 203/1000\n",
      " - 0s - loss: 0.0804 - val_loss: 0.2032\n",
      "Epoch 204/1000\n",
      " - 0s - loss: 0.0835 - val_loss: 0.2565\n",
      "Epoch 205/1000\n",
      " - 0s - loss: 0.1022 - val_loss: 0.2314\n",
      "Epoch 206/1000\n",
      " - 0s - loss: 0.0927 - val_loss: 0.2183\n",
      "Epoch 207/1000\n",
      " - 0s - loss: 0.0873 - val_loss: 0.2586\n",
      "Epoch 208/1000\n",
      " - 0s - loss: 0.0968 - val_loss: 0.1994\n",
      "Epoch 209/1000\n",
      " - 0s - loss: 0.1384 - val_loss: 0.2007\n",
      "Epoch 210/1000\n",
      " - 0s - loss: 0.0887 - val_loss: 0.2549\n",
      "Epoch 211/1000\n",
      " - 0s - loss: 0.1068 - val_loss: 0.2591\n",
      "Epoch 212/1000\n",
      " - 0s - loss: 0.0949 - val_loss: 0.2057\n",
      "Epoch 213/1000\n",
      " - 0s - loss: 0.0984 - val_loss: 0.2161\n",
      "Epoch 214/1000\n",
      " - 0s - loss: 0.1014 - val_loss: 0.1956\n",
      "Epoch 215/1000\n",
      " - 0s - loss: 0.0901 - val_loss: 0.2314\n",
      "Epoch 216/1000\n",
      " - 0s - loss: 0.0808 - val_loss: 0.2268\n",
      "Epoch 217/1000\n",
      " - 0s - loss: 0.0972 - val_loss: 0.2014\n",
      "Epoch 218/1000\n",
      " - 0s - loss: 0.0868 - val_loss: 0.2112\n",
      "Epoch 219/1000\n",
      " - 0s - loss: 0.0631 - val_loss: 0.2370\n",
      "Epoch 220/1000\n",
      " - 0s - loss: 0.1060 - val_loss: 0.1983\n",
      "Epoch 221/1000\n",
      " - 0s - loss: 0.0895 - val_loss: 0.2083\n",
      "Epoch 222/1000\n",
      " - 0s - loss: 0.0853 - val_loss: 0.2328\n",
      "Epoch 223/1000\n",
      " - 0s - loss: 0.1025 - val_loss: 0.1990\n",
      "Epoch 224/1000\n",
      " - 0s - loss: 0.0783 - val_loss: 0.1935\n",
      "Epoch 225/1000\n",
      " - 0s - loss: 0.0922 - val_loss: 0.2010\n",
      "Epoch 226/1000\n",
      " - 0s - loss: 0.1038 - val_loss: 0.2677\n",
      "Epoch 227/1000\n",
      " - 0s - loss: 0.1202 - val_loss: 0.2240\n",
      "Epoch 228/1000\n",
      " - 0s - loss: 0.1079 - val_loss: 0.1999\n",
      "Epoch 229/1000\n",
      " - 0s - loss: 0.0691 - val_loss: 0.2282\n",
      "Epoch 230/1000\n",
      " - 0s - loss: 0.0794 - val_loss: 0.2403\n",
      "Epoch 231/1000\n",
      " - 0s - loss: 0.0795 - val_loss: 0.2007\n",
      "Epoch 232/1000\n",
      " - 0s - loss: 0.0807 - val_loss: 0.2340\n",
      "Epoch 233/1000\n",
      " - 0s - loss: 0.0760 - val_loss: 0.2169\n",
      "Epoch 234/1000\n",
      " - 0s - loss: 0.0684 - val_loss: 0.2315\n",
      "Epoch 235/1000\n",
      " - 0s - loss: 0.0819 - val_loss: 0.2282\n",
      "Epoch 236/1000\n",
      " - 0s - loss: 0.0799 - val_loss: 0.2004\n",
      "Epoch 237/1000\n",
      " - 0s - loss: 0.0828 - val_loss: 0.2258\n",
      "Epoch 238/1000\n",
      " - 0s - loss: 0.0817 - val_loss: 0.2180\n",
      "Epoch 239/1000\n",
      " - 0s - loss: 0.0981 - val_loss: 0.2136\n",
      "Epoch 240/1000\n",
      " - 0s - loss: 0.0861 - val_loss: 0.2042\n",
      "Epoch 241/1000\n",
      " - 0s - loss: 0.0919 - val_loss: 0.1931\n",
      "Epoch 242/1000\n",
      " - 0s - loss: 0.0980 - val_loss: 0.2057\n",
      "Epoch 243/1000\n",
      " - 0s - loss: 0.0816 - val_loss: 0.2375\n",
      "Epoch 244/1000\n",
      " - 0s - loss: 0.0873 - val_loss: 0.2291\n",
      "Epoch 245/1000\n",
      " - 0s - loss: 0.0927 - val_loss: 0.2054\n",
      "Epoch 246/1000\n",
      " - 0s - loss: 0.0647 - val_loss: 0.2307\n",
      "Epoch 247/1000\n",
      " - 0s - loss: 0.0736 - val_loss: 0.2146\n",
      "Epoch 248/1000\n",
      " - 0s - loss: 0.0634 - val_loss: 0.2395\n",
      "Epoch 249/1000\n",
      " - 0s - loss: 0.0846 - val_loss: 0.2333\n",
      "Epoch 250/1000\n",
      " - 0s - loss: 0.0836 - val_loss: 0.1972\n",
      "Epoch 251/1000\n",
      " - 0s - loss: 0.1286 - val_loss: 0.1996\n",
      "Epoch 252/1000\n",
      " - 0s - loss: 0.0832 - val_loss: 0.2400\n",
      "Epoch 253/1000\n",
      " - 0s - loss: 0.0749 - val_loss: 0.2063\n",
      "Epoch 254/1000\n",
      " - 0s - loss: 0.0978 - val_loss: 0.1919\n",
      "Epoch 255/1000\n",
      " - 0s - loss: 0.0776 - val_loss: 0.2395\n",
      "Epoch 256/1000\n",
      " - 0s - loss: 0.0913 - val_loss: 0.2241\n",
      "Epoch 257/1000\n",
      " - 0s - loss: 0.0893 - val_loss: 0.1970\n",
      "Epoch 258/1000\n",
      " - 0s - loss: 0.0737 - val_loss: 0.2380\n",
      "Epoch 259/1000\n",
      " - 0s - loss: 0.0658 - val_loss: 0.1988\n",
      "Epoch 260/1000\n",
      " - 0s - loss: 0.1060 - val_loss: 0.1939\n",
      "Epoch 261/1000\n",
      " - 0s - loss: 0.0691 - val_loss: 0.2245\n",
      "Epoch 262/1000\n",
      " - 0s - loss: 0.0768 - val_loss: 0.2514\n",
      "Epoch 263/1000\n",
      " - 0s - loss: 0.1040 - val_loss: 0.2182\n",
      "Epoch 264/1000\n",
      " - 0s - loss: 0.0807 - val_loss: 0.2037\n",
      "Epoch 265/1000\n",
      " - 0s - loss: 0.0693 - val_loss: 0.2365\n",
      "Epoch 266/1000\n",
      " - 0s - loss: 0.0665 - val_loss: 0.1980\n",
      "Epoch 267/1000\n",
      " - 0s - loss: 0.0736 - val_loss: 0.2135\n",
      "Epoch 268/1000\n",
      " - 0s - loss: 0.0689 - val_loss: 0.2463\n",
      "Epoch 269/1000\n",
      " - 0s - loss: 0.0854 - val_loss: 0.2282\n",
      "Epoch 270/1000\n",
      " - 0s - loss: 0.0821 - val_loss: 0.2345\n",
      "Epoch 271/1000\n",
      " - 0s - loss: 0.0763 - val_loss: 0.2093\n",
      "Epoch 272/1000\n",
      " - 0s - loss: 0.0564 - val_loss: 0.2448\n",
      "Epoch 273/1000\n",
      " - 0s - loss: 0.0781 - val_loss: 0.2609\n",
      "Epoch 274/1000\n",
      " - 0s - loss: 0.0874 - val_loss: 0.2190\n",
      "Epoch 275/1000\n",
      " - 0s - loss: 0.0991 - val_loss: 0.2064\n",
      "Epoch 276/1000\n",
      " - 0s - loss: 0.0738 - val_loss: 0.2558\n",
      "Epoch 277/1000\n",
      " - 0s - loss: 0.0934 - val_loss: 0.2500\n",
      "Epoch 278/1000\n",
      " - 0s - loss: 0.0847 - val_loss: 0.1970\n",
      "Epoch 279/1000\n",
      " - 0s - loss: 0.0811 - val_loss: 0.2218\n",
      "Epoch 280/1000\n",
      " - 0s - loss: 0.0878 - val_loss: 0.2463\n",
      "Epoch 281/1000\n",
      " - 0s - loss: 0.0744 - val_loss: 0.2198\n",
      "Epoch 282/1000\n",
      " - 0s - loss: 0.0687 - val_loss: 0.2139\n",
      "Epoch 283/1000\n",
      " - 0s - loss: 0.0956 - val_loss: 0.2250\n",
      "Epoch 284/1000\n",
      " - 0s - loss: 0.0805 - val_loss: 0.2564\n",
      "Epoch 285/1000\n",
      " - 0s - loss: 0.0753 - val_loss: 0.2019\n",
      "Epoch 286/1000\n",
      " - 0s - loss: 0.0841 - val_loss: 0.2119\n",
      "Epoch 287/1000\n",
      " - 0s - loss: 0.0671 - val_loss: 0.2078\n",
      "Epoch 288/1000\n",
      " - 0s - loss: 0.0707 - val_loss: 0.2131\n",
      "Epoch 289/1000\n",
      " - 0s - loss: 0.0756 - val_loss: 0.2212\n",
      "Epoch 290/1000\n",
      " - 0s - loss: 0.0576 - val_loss: 0.2001\n",
      "Epoch 291/1000\n",
      " - 0s - loss: 0.0704 - val_loss: 0.2405\n",
      "Epoch 292/1000\n",
      " - 0s - loss: 0.0764 - val_loss: 0.2342\n",
      "Epoch 293/1000\n",
      " - 0s - loss: 0.0753 - val_loss: 0.2187\n",
      "Epoch 294/1000\n",
      " - 0s - loss: 0.0808 - val_loss: 0.2128\n",
      "Epoch 295/1000\n",
      " - 0s - loss: 0.0669 - val_loss: 0.2012\n",
      "Epoch 296/1000\n",
      " - 0s - loss: 0.0680 - val_loss: 0.2144\n",
      "Epoch 297/1000\n",
      " - 0s - loss: 0.0649 - val_loss: 0.1962\n",
      "Epoch 298/1000\n",
      " - 0s - loss: 0.1030 - val_loss: 0.1958\n",
      "Epoch 299/1000\n",
      " - 0s - loss: 0.0686 - val_loss: 0.2185\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0737 - val_loss: 0.2017\n",
      "Epoch 301/1000\n",
      " - 0s - loss: 0.0586 - val_loss: 0.2108\n",
      "Epoch 302/1000\n",
      " - 0s - loss: 0.0734 - val_loss: 0.2318\n",
      "Epoch 303/1000\n",
      " - 0s - loss: 0.0685 - val_loss: 0.2031\n",
      "Epoch 304/1000\n",
      " - 0s - loss: 0.0759 - val_loss: 0.2099\n",
      "Epoch 305/1000\n",
      " - 0s - loss: 0.0799 - val_loss: 0.2460\n",
      "Epoch 306/1000\n",
      " - 0s - loss: 0.0764 - val_loss: 0.2047\n",
      "Epoch 307/1000\n",
      " - 0s - loss: 0.0629 - val_loss: 0.2058\n",
      "Epoch 308/1000\n",
      " - 0s - loss: 0.0597 - val_loss: 0.2353\n",
      "Epoch 309/1000\n",
      " - 0s - loss: 0.0786 - val_loss: 0.2298\n",
      "Epoch 310/1000\n",
      " - 0s - loss: 0.0830 - val_loss: 0.2144\n",
      "Epoch 311/1000\n",
      " - 0s - loss: 0.0687 - val_loss: 0.2438\n",
      "Epoch 312/1000\n",
      " - 0s - loss: 0.0888 - val_loss: 0.2115\n",
      "Epoch 313/1000\n",
      " - 0s - loss: 0.0725 - val_loss: 0.1958\n",
      "Epoch 314/1000\n",
      " - 0s - loss: 0.0732 - val_loss: 0.1991\n",
      "Epoch 315/1000\n",
      " - 0s - loss: 0.0721 - val_loss: 0.2199\n",
      "Epoch 316/1000\n",
      " - 0s - loss: 0.0789 - val_loss: 0.2128\n",
      "Epoch 317/1000\n",
      " - 0s - loss: 0.0656 - val_loss: 0.2022\n",
      "Epoch 318/1000\n",
      " - 0s - loss: 0.0810 - val_loss: 0.2122\n",
      "Epoch 319/1000\n",
      " - 0s - loss: 0.0726 - val_loss: 0.2285\n",
      "Epoch 320/1000\n",
      " - 0s - loss: 0.0741 - val_loss: 0.2172\n",
      "Epoch 321/1000\n",
      " - 0s - loss: 0.0644 - val_loss: 0.2201\n",
      "Epoch 322/1000\n",
      " - 0s - loss: 0.0582 - val_loss: 0.2241\n",
      "Epoch 323/1000\n",
      " - 0s - loss: 0.0817 - val_loss: 0.2205\n",
      "Epoch 324/1000\n",
      " - 0s - loss: 0.0705 - val_loss: 0.1973\n",
      "Epoch 325/1000\n",
      " - 0s - loss: 0.0746 - val_loss: 0.2127\n",
      "Epoch 326/1000\n",
      " - 0s - loss: 0.0704 - val_loss: 0.2096\n",
      "Epoch 327/1000\n",
      " - 0s - loss: 0.0790 - val_loss: 0.2178\n",
      "Epoch 328/1000\n",
      " - 0s - loss: 0.0640 - val_loss: 0.2177\n",
      "Epoch 329/1000\n",
      " - 0s - loss: 0.0769 - val_loss: 0.2195\n",
      "Epoch 330/1000\n",
      " - 0s - loss: 0.0646 - val_loss: 0.2422\n",
      "Epoch 331/1000\n",
      " - 0s - loss: 0.0997 - val_loss: 0.2311\n",
      "Epoch 332/1000\n",
      " - 0s - loss: 0.0736 - val_loss: 0.2123\n",
      "Epoch 333/1000\n",
      " - 0s - loss: 0.0871 - val_loss: 0.2320\n",
      "Epoch 334/1000\n",
      " - 0s - loss: 0.1011 - val_loss: 0.2468\n",
      "Epoch 335/1000\n",
      " - 0s - loss: 0.0704 - val_loss: 0.2143\n",
      "Epoch 336/1000\n",
      " - 0s - loss: 0.0771 - val_loss: 0.2237\n",
      "Epoch 337/1000\n",
      " - 0s - loss: 0.0529 - val_loss: 0.2210\n",
      "Epoch 338/1000\n",
      " - 0s - loss: 0.0683 - val_loss: 0.2301\n",
      "Epoch 339/1000\n",
      " - 0s - loss: 0.0662 - val_loss: 0.2405\n",
      "Epoch 340/1000\n",
      " - 0s - loss: 0.0640 - val_loss: 0.2397\n",
      "Epoch 341/1000\n",
      " - 0s - loss: 0.0549 - val_loss: 0.2423\n",
      "Epoch 342/1000\n",
      " - 0s - loss: 0.0677 - val_loss: 0.2255\n",
      "Epoch 343/1000\n",
      " - 0s - loss: 0.0646 - val_loss: 0.2544\n",
      "Epoch 344/1000\n",
      " - 0s - loss: 0.0948 - val_loss: 0.2565\n",
      "Epoch 345/1000\n",
      " - 0s - loss: 0.0689 - val_loss: 0.2113\n",
      "Epoch 346/1000\n",
      " - 0s - loss: 0.0956 - val_loss: 0.2108\n",
      "Epoch 347/1000\n",
      " - 0s - loss: 0.0389 - val_loss: 0.2319\n",
      "Epoch 348/1000\n",
      " - 0s - loss: 0.0757 - val_loss: 0.2205\n",
      "Epoch 349/1000\n",
      " - 0s - loss: 0.0772 - val_loss: 0.2230\n",
      "Epoch 350/1000\n",
      " - 0s - loss: 0.0685 - val_loss: 0.2320\n",
      "Epoch 351/1000\n",
      " - 0s - loss: 0.0533 - val_loss: 0.2560\n",
      "Epoch 352/1000\n",
      " - 0s - loss: 0.0763 - val_loss: 0.2602\n",
      "Epoch 353/1000\n",
      " - 0s - loss: 0.0894 - val_loss: 0.2251\n",
      "Epoch 354/1000\n",
      " - 0s - loss: 0.0764 - val_loss: 0.2478\n",
      "Epoch 355/1000\n",
      " - 0s - loss: 0.1003 - val_loss: 0.2534\n",
      "Epoch 356/1000\n",
      " - 0s - loss: 0.0711 - val_loss: 0.2294\n",
      "Epoch 357/1000\n",
      " - 0s - loss: 0.0667 - val_loss: 0.2243\n",
      "Epoch 358/1000\n",
      " - 0s - loss: 0.0739 - val_loss: 0.2341\n",
      "Epoch 359/1000\n",
      " - 0s - loss: 0.0584 - val_loss: 0.2151\n",
      "Epoch 360/1000\n",
      " - 0s - loss: 0.0815 - val_loss: 0.2161\n",
      "Epoch 361/1000\n",
      " - 0s - loss: 0.0565 - val_loss: 0.2374\n",
      "Epoch 362/1000\n",
      " - 0s - loss: 0.0795 - val_loss: 0.2329\n",
      "Epoch 363/1000\n",
      " - 0s - loss: 0.0667 - val_loss: 0.2215\n",
      "Epoch 364/1000\n",
      " - 0s - loss: 0.0617 - val_loss: 0.2272\n",
      "Epoch 365/1000\n",
      " - 0s - loss: 0.0724 - val_loss: 0.2299\n",
      "Epoch 366/1000\n",
      " - 0s - loss: 0.0544 - val_loss: 0.2111\n",
      "Epoch 367/1000\n",
      " - 0s - loss: 0.0886 - val_loss: 0.2215\n",
      "Epoch 368/1000\n",
      " - 0s - loss: 0.0595 - val_loss: 0.2302\n",
      "Epoch 369/1000\n",
      " - 0s - loss: 0.0678 - val_loss: 0.2134\n",
      "Epoch 370/1000\n",
      " - 0s - loss: 0.0762 - val_loss: 0.2194\n",
      "Epoch 371/1000\n",
      " - 0s - loss: 0.0603 - val_loss: 0.2370\n",
      "Epoch 372/1000\n",
      " - 0s - loss: 0.0706 - val_loss: 0.2404\n",
      "Epoch 373/1000\n",
      " - 0s - loss: 0.0622 - val_loss: 0.2228\n",
      "Epoch 374/1000\n",
      " - 0s - loss: 0.0637 - val_loss: 0.2257\n",
      "Epoch 375/1000\n",
      " - 0s - loss: 0.0642 - val_loss: 0.2137\n",
      "Epoch 376/1000\n",
      " - 0s - loss: 0.0665 - val_loss: 0.2251\n",
      "Epoch 377/1000\n",
      " - 0s - loss: 0.0556 - val_loss: 0.2261\n",
      "Epoch 378/1000\n",
      " - 0s - loss: 0.0712 - val_loss: 0.2293\n",
      "Epoch 379/1000\n",
      " - 0s - loss: 0.0688 - val_loss: 0.2286\n",
      "Epoch 380/1000\n",
      " - 0s - loss: 0.0539 - val_loss: 0.2240\n",
      "Epoch 381/1000\n",
      " - 0s - loss: 0.0615 - val_loss: 0.2316\n",
      "Epoch 382/1000\n",
      " - 0s - loss: 0.0539 - val_loss: 0.2539\n",
      "Epoch 383/1000\n",
      " - 0s - loss: 0.0749 - val_loss: 0.2439\n",
      "Epoch 384/1000\n",
      " - 0s - loss: 0.0707 - val_loss: 0.2334\n",
      "Epoch 385/1000\n",
      " - 0s - loss: 0.0664 - val_loss: 0.2462\n",
      "Epoch 386/1000\n",
      " - 0s - loss: 0.0648 - val_loss: 0.2480\n",
      "Epoch 387/1000\n",
      " - 0s - loss: 0.0435 - val_loss: 0.2285\n",
      "Epoch 388/1000\n",
      " - 0s - loss: 0.0501 - val_loss: 0.2458\n",
      "Epoch 389/1000\n",
      " - 0s - loss: 0.0672 - val_loss: 0.2307\n",
      "Epoch 390/1000\n",
      " - 0s - loss: 0.0988 - val_loss: 0.2226\n",
      "Epoch 391/1000\n",
      " - 0s - loss: 0.0659 - val_loss: 0.2433\n",
      "Epoch 392/1000\n",
      " - 0s - loss: 0.0832 - val_loss: 0.2334\n",
      "Epoch 393/1000\n",
      " - 0s - loss: 0.0752 - val_loss: 0.2169\n",
      "Epoch 394/1000\n",
      " - 0s - loss: 0.0698 - val_loss: 0.2242\n",
      "Epoch 395/1000\n",
      " - 0s - loss: 0.0719 - val_loss: 0.2326\n",
      "Epoch 396/1000\n",
      " - 0s - loss: 0.0526 - val_loss: 0.2127\n",
      "Epoch 397/1000\n",
      " - 0s - loss: 0.0677 - val_loss: 0.2102\n",
      "Epoch 398/1000\n",
      " - 0s - loss: 0.0766 - val_loss: 0.2287\n",
      "Epoch 399/1000\n",
      " - 0s - loss: 0.0752 - val_loss: 0.2473\n",
      "Epoch 400/1000\n",
      " - 0s - loss: 0.0734 - val_loss: 0.2225\n",
      "Epoch 401/1000\n",
      " - 0s - loss: 0.0835 - val_loss: 0.2116\n",
      "Epoch 402/1000\n",
      " - 0s - loss: 0.0692 - val_loss: 0.2279\n",
      "Epoch 403/1000\n",
      " - 0s - loss: 0.0548 - val_loss: 0.2245\n",
      "Epoch 404/1000\n",
      " - 0s - loss: 0.0561 - val_loss: 0.2305\n",
      "Epoch 405/1000\n",
      " - 0s - loss: 0.0667 - val_loss: 0.2306\n",
      "Epoch 406/1000\n",
      " - 0s - loss: 0.0610 - val_loss: 0.2343\n",
      "Epoch 407/1000\n",
      " - 0s - loss: 0.0534 - val_loss: 0.2454\n",
      "Epoch 408/1000\n",
      " - 0s - loss: 0.0746 - val_loss: 0.2356\n",
      "Epoch 409/1000\n",
      " - 0s - loss: 0.0600 - val_loss: 0.2297\n",
      "Epoch 410/1000\n",
      " - 0s - loss: 0.0513 - val_loss: 0.2538\n",
      "Epoch 411/1000\n",
      " - 0s - loss: 0.0887 - val_loss: 0.2252\n",
      "Epoch 412/1000\n",
      " - 0s - loss: 0.0605 - val_loss: 0.2188\n",
      "Epoch 413/1000\n",
      " - 0s - loss: 0.0674 - val_loss: 0.2282\n",
      "Epoch 414/1000\n",
      " - 0s - loss: 0.0689 - val_loss: 0.2503\n",
      "Epoch 415/1000\n",
      " - 1s - loss: 0.0497 - val_loss: 0.2326\n",
      "Epoch 416/1000\n",
      " - 1s - loss: 0.0448 - val_loss: 0.2359\n",
      "Epoch 417/1000\n",
      " - 1s - loss: 0.0520 - val_loss: 0.2385\n",
      "Epoch 418/1000\n",
      " - 1s - loss: 0.0503 - val_loss: 0.2271\n",
      "Epoch 419/1000\n",
      " - 2s - loss: 0.0470 - val_loss: 0.2326\n",
      "Epoch 420/1000\n",
      " - 1s - loss: 0.0526 - val_loss: 0.2294\n",
      "Epoch 421/1000\n",
      " - 2s - loss: 0.0635 - val_loss: 0.2211\n",
      "Epoch 422/1000\n",
      " - 1s - loss: 0.0529 - val_loss: 0.2487\n",
      "Epoch 423/1000\n",
      " - 1s - loss: 0.0775 - val_loss: 0.2562\n",
      "Epoch 424/1000\n",
      " - 1s - loss: 0.0738 - val_loss: 0.2164\n",
      "Epoch 425/1000\n",
      " - 1s - loss: 0.0857 - val_loss: 0.2252\n",
      "Epoch 426/1000\n",
      " - 2s - loss: 0.0571 - val_loss: 0.2280\n",
      "Epoch 427/1000\n",
      " - 2s - loss: 0.0615 - val_loss: 0.2249\n",
      "Epoch 428/1000\n",
      " - 1s - loss: 0.0497 - val_loss: 0.2231\n",
      "Epoch 429/1000\n",
      " - 1s - loss: 0.0402 - val_loss: 0.2284\n",
      "Epoch 430/1000\n",
      " - 1s - loss: 0.0482 - val_loss: 0.2352\n",
      "Epoch 431/1000\n",
      " - 1s - loss: 0.0657 - val_loss: 0.2214\n",
      "Epoch 432/1000\n",
      " - 1s - loss: 0.0883 - val_loss: 0.2216\n",
      "Epoch 433/1000\n",
      " - 1s - loss: 0.0462 - val_loss: 0.2572\n",
      "Epoch 434/1000\n",
      " - 1s - loss: 0.0899 - val_loss: 0.2527\n",
      "Epoch 435/1000\n",
      " - 1s - loss: 0.0481 - val_loss: 0.2357\n",
      "Epoch 436/1000\n",
      " - 1s - loss: 0.0638 - val_loss: 0.2301\n",
      "Epoch 437/1000\n",
      " - 1s - loss: 0.0511 - val_loss: 0.2185\n",
      "Epoch 438/1000\n",
      " - 1s - loss: 0.0562 - val_loss: 0.2106\n",
      "Epoch 439/1000\n",
      " - 1s - loss: 0.0688 - val_loss: 0.2288\n",
      "Epoch 440/1000\n",
      " - 1s - loss: 0.0569 - val_loss: 0.2256\n",
      "Epoch 441/1000\n",
      " - 1s - loss: 0.0460 - val_loss: 0.2360\n",
      "Epoch 442/1000\n",
      " - 1s - loss: 0.0519 - val_loss: 0.2356\n",
      "Epoch 443/1000\n",
      " - 1s - loss: 0.0491 - val_loss: 0.2441\n",
      "Epoch 444/1000\n",
      " - 1s - loss: 0.0480 - val_loss: 0.2334\n",
      "Epoch 445/1000\n",
      " - 1s - loss: 0.0567 - val_loss: 0.2452\n",
      "Epoch 446/1000\n",
      " - 1s - loss: 0.0423 - val_loss: 0.2617\n",
      "Epoch 447/1000\n",
      " - 1s - loss: 0.0639 - val_loss: 0.2692\n",
      "Epoch 448/1000\n",
      " - 1s - loss: 0.0661 - val_loss: 0.2430\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.0642 - val_loss: 0.2328\n",
      "Epoch 450/1000\n",
      " - 1s - loss: 0.0700 - val_loss: 0.2515\n",
      "Epoch 451/1000\n",
      " - 1s - loss: 0.0635 - val_loss: 0.2244\n",
      "Epoch 452/1000\n",
      " - 1s - loss: 0.0672 - val_loss: 0.2135\n",
      "Epoch 453/1000\n",
      " - 1s - loss: 0.0618 - val_loss: 0.2387\n",
      "Epoch 454/1000\n",
      " - 1s - loss: 0.0576 - val_loss: 0.2354\n",
      "Epoch 455/1000\n",
      " - 1s - loss: 0.0551 - val_loss: 0.2184\n",
      "Epoch 456/1000\n",
      " - 1s - loss: 0.0599 - val_loss: 0.2324\n",
      "Epoch 457/1000\n",
      " - 1s - loss: 0.0567 - val_loss: 0.2379\n",
      "Epoch 458/1000\n",
      " - 1s - loss: 0.0592 - val_loss: 0.2289\n",
      "Epoch 459/1000\n",
      " - 1s - loss: 0.0438 - val_loss: 0.2339\n",
      "Epoch 460/1000\n",
      " - 1s - loss: 0.0503 - val_loss: 0.2176\n",
      "Epoch 461/1000\n",
      " - 1s - loss: 0.0589 - val_loss: 0.2198\n",
      "Epoch 462/1000\n",
      " - 1s - loss: 0.0625 - val_loss: 0.2349\n",
      "Epoch 463/1000\n",
      " - 1s - loss: 0.0641 - val_loss: 0.2247\n",
      "Epoch 464/1000\n",
      " - 1s - loss: 0.0477 - val_loss: 0.2076\n",
      "Epoch 465/1000\n",
      " - 1s - loss: 0.0952 - val_loss: 0.2118\n",
      "Epoch 466/1000\n",
      " - 1s - loss: 0.0507 - val_loss: 0.2396\n",
      "Epoch 467/1000\n",
      " - 1s - loss: 0.0801 - val_loss: 0.2311\n",
      "Epoch 468/1000\n",
      " - 1s - loss: 0.0748 - val_loss: 0.2159\n",
      "Epoch 469/1000\n",
      " - 1s - loss: 0.0701 - val_loss: 0.2187\n",
      "Epoch 470/1000\n",
      " - 1s - loss: 0.0477 - val_loss: 0.2239\n",
      "Epoch 471/1000\n",
      " - 1s - loss: 0.0407 - val_loss: 0.2287\n",
      "Epoch 472/1000\n",
      " - 1s - loss: 0.0574 - val_loss: 0.2323\n",
      "Epoch 473/1000\n",
      " - 1s - loss: 0.0374 - val_loss: 0.2368\n",
      "Epoch 474/1000\n",
      " - 1s - loss: 0.0547 - val_loss: 0.2431\n",
      "Epoch 475/1000\n",
      " - 1s - loss: 0.0392 - val_loss: 0.2441\n",
      "Epoch 476/1000\n",
      " - 1s - loss: 0.0501 - val_loss: 0.2377\n",
      "Epoch 477/1000\n",
      " - 1s - loss: 0.0434 - val_loss: 0.2335\n",
      "Epoch 478/1000\n",
      " - 1s - loss: 0.0642 - val_loss: 0.2373\n",
      "Epoch 479/1000\n",
      " - 1s - loss: 0.0506 - val_loss: 0.2263\n",
      "Epoch 480/1000\n",
      " - 1s - loss: 0.0526 - val_loss: 0.2452\n",
      "Epoch 481/1000\n",
      " - 1s - loss: 0.0598 - val_loss: 0.2566\n",
      "Epoch 482/1000\n",
      " - 1s - loss: 0.0602 - val_loss: 0.2437\n",
      "Epoch 483/1000\n",
      " - 1s - loss: 0.0449 - val_loss: 0.2419\n",
      "Epoch 484/1000\n",
      " - 1s - loss: 0.0412 - val_loss: 0.2411\n",
      "Epoch 485/1000\n",
      " - 1s - loss: 0.0425 - val_loss: 0.2352\n",
      "Epoch 486/1000\n",
      " - 1s - loss: 0.0451 - val_loss: 0.2375\n",
      "Epoch 487/1000\n",
      " - 1s - loss: 0.0543 - val_loss: 0.2329\n",
      "Epoch 488/1000\n",
      " - 1s - loss: 0.0644 - val_loss: 0.2236\n",
      "Epoch 489/1000\n",
      " - 1s - loss: 0.0624 - val_loss: 0.2230\n",
      "Epoch 490/1000\n",
      " - 1s - loss: 0.0524 - val_loss: 0.2179\n",
      "Epoch 491/1000\n",
      " - 1s - loss: 0.0480 - val_loss: 0.2267\n",
      "Epoch 492/1000\n",
      " - 1s - loss: 0.0601 - val_loss: 0.2203\n",
      "Epoch 493/1000\n",
      " - 1s - loss: 0.0525 - val_loss: 0.2128\n",
      "Epoch 494/1000\n",
      " - 1s - loss: 0.0701 - val_loss: 0.2191\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build networks. Loop n times to deal with ranodmness.\n",
    "n_loops = 10\n",
    "rmses, maes = [], []\n",
    "best_rmse, best_mae = 100, 100\n",
    "best_model = None\n",
    "best_preds = []\n",
    "\n",
    "for i in range(0, n_loops):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(30, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(LSTM(30))\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    \n",
    "    # Fit network\n",
    "    lstm_model = model.fit(X_train, y_train, epochs=1000, batch_size=5, validation_data=(X_test, y_test), verbose=2, shuffle=False)\n",
    "    \n",
    "    # Make predictions for test set\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    # Invert scaling for preds\n",
    "    preds_inv = np.concatenate((preds, test[:,1:]), axis=1)\n",
    "    preds_inv = scaler.inverse_transform(preds_inv)\n",
    "    preds_inv = preds_inv[:,0]\n",
    "    \n",
    "    # Calculate RMSE and MAE\n",
    "    rmses.append(np.sqrt(mean_squared_error(y_inv, preds_inv)))\n",
    "    maes.append(mean_absolute_error(y_inv, preds_inv))\n",
    "    \n",
    "    if maes[i] < best_mae:\n",
    "        best_rmse = rmses[i]\n",
    "        best_mae = maes[i]\n",
    "        best_model = lstm_model\n",
    "        best_preds = preds_inv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot loss curve for best model\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "\n",
    "plt.plot(best_model.history['loss'], label='train')\n",
    "plt.plot(best_model.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print RMSES and MAES\n",
    "print('Best RMSE: {:.2f}'.format(best_rmse))\n",
    "print('Best MAE: {:.2f}'.format(best_mae))\n",
    "print('Average RMSE: {:.2f}'.format(np.mean(rmses)))\n",
    "print('Average MAE: {:.2f}'.format(np.mean(maes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([maes, rmses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "fig, ax = plt.subplots()\n",
    "plot1 = ax.plot(y_inv, alpha = 0.8, label='actual')\n",
    "plot1 = ax.plot(best_preds, alpha = 0.8, label='predicted')\n",
    "ax.legend()\n",
    "plt.xlabel('Week (2012)')\n",
    "plt.ylabel('Fantasy Points')\n",
    "plt.title('Tom Brady Fantasy Points 2012, Predicted vs Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iterative Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild network for iterative training - stateful model with one batch\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, batch_input_shape=(1, X_train.shape[1], X_train.shape[2]), stateful=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "for i in range(50):\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size=1, verbose=0, shuffle=False)\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(y_test)):\n",
    "    X_test_formatted = X_test[i].reshape(X_test[i].shape[0], 1, X_test[i].shape[1])\n",
    "    preds.append(model.predict(X_test_formatted)[0])\n",
    "    X_train_upd = np.append(X_train, X_test_formatted, axis=0)\n",
    "    y_train_upd = np.append(y_train, y_test[i])\n",
    "    model.fit(X_train_upd, y_train_upd, epochs=10, batch_size=1, verbose=0, shuffle=False)\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 8.38\n",
      "MAE: 6.80\n"
     ]
    }
   ],
   "source": [
    "preds_inv = np.concatenate((preds, X_test_orig), axis=1)\n",
    "preds_inv = scaler.inverse_transform(preds_inv)\n",
    "preds_inv = preds_inv[:,0]\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_inv, preds_inv))\n",
    "mae = mean_absolute_error(y_inv, preds_inv)\n",
    "print('RMSE: {:.2f}'.format(rmse))\n",
    "print('MAE: {:.2f}'.format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "fig, ax = plt.subplots()\n",
    "bar1 = ax.bar(x = np.arange(0, len(y_inv)) - .25, height=y_inv, width=.4, alpha = 0.8, label='actual')\n",
    "bar2 = ax.bar(x = np.arange(0, len(preds_inv)) + .25, height=preds_inv, width=.4, alpha = 0.8, label='predicted')\n",
    "ax.legend()\n",
    "plt.xlabel('Week (2012)')\n",
    "plt.ylabel('Fantasy Points')\n",
    "plt.title('Tom Brady Fantasy Points 2012, Predicted vs Actual (Iterative Training)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
